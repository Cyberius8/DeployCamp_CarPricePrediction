{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "59969b94",
      "metadata": {
        "id": "59969b94"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_search_models_cv_compare(X, y, scoring='r2', cv_list=[3, 5, 10]):\n",
        "    \"\"\"\n",
        "    Melakukan GridSearchCV untuk Linear Regression, Random Forest, dan XGBoost\n",
        "    dengan berbagai nilai CV untuk membandingkan performa.\n",
        "\n",
        "    Parameters:\n",
        "    - X : pd.DataFrame, fitur input\n",
        "    - y : pd.Series/array, target output\n",
        "    - scoring : str, metrik evaluasi (default='r2')\n",
        "    - cv_list : list of int, daftar nilai split CV yang ingin diuji\n",
        "\n",
        "    Returns:\n",
        "    - results : dict berisi hasil tiap model dan tiap nilai CV\n",
        "    \"\"\"\n",
        "    from sklearn.model_selection import GridSearchCV, KFold\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    from xgboost import XGBRegressor\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for cv_split in cv_list:\n",
        "        cv = KFold(n_splits=cv_split, shuffle=True, random_state=42)\n",
        "\n",
        "        results[cv_split] = {}\n",
        "\n",
        "        # 1. Linear Regression\n",
        "        pipe_lr = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('model', LinearRegression())\n",
        "        ])\n",
        "        param_lr = {}\n",
        "        grid_lr = GridSearchCV(pipe_lr, param_lr, cv=cv, scoring=scoring)\n",
        "        grid_lr.fit(X, y)\n",
        "        results[cv_split]['Linear Regression'] = {\n",
        "            'Best Score': grid_lr.best_score_,\n",
        "            'Best Params': grid_lr.best_params_\n",
        "        }\n",
        "\n",
        "        # 2. Random Forest\n",
        "        pipe_rf = Pipeline([\n",
        "            ('model', RandomForestRegressor(random_state=42))\n",
        "        ])\n",
        "        param_rf = {\n",
        "            'model__n_estimators': [50, 100],\n",
        "            'model__max_depth': [None, 5, 10],\n",
        "            'model__min_samples_split': [2, 5],\n",
        "            'model__min_samples_leaf': [1, 2]\n",
        "        }\n",
        "        grid_rf = GridSearchCV(pipe_rf, param_rf, cv=cv, scoring=scoring, n_jobs=-1)\n",
        "        grid_rf.fit(X, y)\n",
        "        results[cv_split]['Random Forest'] = {\n",
        "            'Best Score': grid_rf.best_score_,\n",
        "            'Best Params': grid_rf.best_params_\n",
        "        }\n",
        "\n",
        "        # 3. XGBoost\n",
        "        pipe_xgb = Pipeline([\n",
        "            ('model', XGBRegressor(objective='reg:squarederror', random_state=42, verbosity=0))\n",
        "        ])\n",
        "        param_xgb = {\n",
        "            'model__n_estimators': [50, 100],\n",
        "            'model__max_depth': [3, 5, 10],\n",
        "            'model__learning_rate': [0.01, 0.1],\n",
        "            'model__subsample': [0.7, 1],\n",
        "            'model__colsample_bytree': [0.7, 1]\n",
        "        }\n",
        "        grid_xgb = GridSearchCV(pipe_xgb, param_xgb, cv=cv, scoring=scoring, n_jobs=-1)\n",
        "        grid_xgb.fit(X, y)\n",
        "        results[cv_split]['XGBoost'] = {\n",
        "            'Best Score': grid_xgb.best_score_,\n",
        "            'Best Params': grid_xgb.best_params_\n",
        "        }\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "j9E4CZAbNv9U"
      },
      "id": "j9E4CZAbNv9U",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a5e4396b",
      "metadata": {
        "id": "a5e4396b",
        "outputId": "7bbac012-0d70-446c-9a03-d4b0d01842a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸš€ Running GridSearch with CV=3\n",
            "\n",
            "ðŸš€ Running GridSearch with CV=5\n",
            "\n",
            "ðŸš€ Running GridSearch with CV=10\n",
            "\n",
            "=== CV=3 ===\n",
            "Linear Regression: R2 = 0.8299, Params = {}\n",
            "Random Forest: R2 = 0.9251, Params = {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
            "XGBoost: R2 = 0.9220, Params = {'model__colsample_bytree': 1, 'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__subsample': 0.7}\n",
            "\n",
            "=== CV=5 ===\n",
            "Linear Regression: R2 = 0.8433, Params = {}\n",
            "Random Forest: R2 = 0.9336, Params = {'model__max_depth': 10, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
            "XGBoost: R2 = 0.9298, Params = {'model__colsample_bytree': 0.7, 'model__learning_rate': 0.1, 'model__max_depth': 10, 'model__n_estimators': 100, 'model__subsample': 0.7}\n",
            "\n",
            "=== CV=10 ===\n",
            "Linear Regression: R2 = 0.8432, Params = {}\n",
            "Random Forest: R2 = 0.9170, Params = {'model__max_depth': 10, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
            "XGBoost: R2 = 0.9238, Params = {'model__colsample_bytree': 0.7, 'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__n_estimators': 100, 'model__subsample': 1}\n"
          ]
        }
      ],
      "source": [
        "cv_results = grid_search_models_cv_compare(X, y, scoring='r2', cv_list=[3, 5, 10])\n",
        "\n",
        "# Menampilkan hasil\n",
        "for cv_split, models in cv_results.items():\n",
        "    print(f\"\\n=== CV={cv_split} ===\")\n",
        "    for model_name, info in models.items():\n",
        "        print(f\"{model_name}: R2 = {info['Best Score']:.4f}, Params = {info['Best Params']}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}