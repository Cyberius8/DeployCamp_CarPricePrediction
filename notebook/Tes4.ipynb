{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac13c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "pd.set_option('display.max_rows', 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c304d7",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "    # n_estimators: It defines the number of trees in the forest.\n",
    "    # max_features: Limits the number of features to consider when splitting a node.\n",
    "    # max_depth: Controls the maximum depth of each tree.\n",
    "    # max_leaf_nodes: Limits the number of leaf nodes in the tree hence controlling its size and complexity.\n",
    "    # max_sample: Apart from the features, we have a large set of training datasets.\n",
    "    # min_sample_split: Specifies the minimum number of samples required to split an internal node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf50b4a",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "    # learning_rate: Step size shrinkage\n",
    "    # max_depth: Max tree depth\n",
    "    # n_estimators: Number of trees\n",
    "    # subsample: Fraction of data used per tree\n",
    "    # colsample_bytree: Fraction of features per tree\n",
    "    # reg_alpha: L1 regularization\n",
    "    # reg_lambda: L2 regularization\n",
    "    # gamma: Minimum loss reduction to make further partition\n",
    "    # booster: Type of booster: gbtree, gblinear, dart\n",
    "    # tree_method: Can be 'exact', 'approx', 'hist'\n",
    "    # scale_pos_weight: Useful for imbalanced data\n",
    "    # early_stopping_rounds: Stops training early if no improvement.\n",
    "    # eval_metric: Evaluation metric (e.g., 'auc', 'logloss')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59969b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_models(X, y, cv_splits=5, scoring='r2', Model='All'):\n",
    "    \"\"\"\n",
    "    Melakukan grid search untuk model Random Forest dan/atau XGBoost.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Fitur input (DataFrame)\n",
    "    - y: Target variabel\n",
    "    - cv_splits: Jumlah CV split (default: 5)\n",
    "    - scoring: Metode evaluasi (default: 'r2')\n",
    "    - Model: 'RF', 'XGB', atau 'All' (default: 'All')\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary dengan hasil grid search dari model-model yang dipilih\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    cv = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    if Model in ['RF', 'All']:\n",
    "        pipe_rf = Pipeline([\n",
    "            ('model', RandomForestRegressor(random_state=42))\n",
    "        ])\n",
    "        param_rf = {\n",
    "            'model__n_estimators': [50, 100, 200],\n",
    "            'model__max_features': ['sqrt', 'log2'],\n",
    "            'model__max_depth': [None, 10, 20, 30],\n",
    "            'model__max_leaf_nodes': [None, 10, 20],\n",
    "            'model__max_samples': [None, 0.5, 0.7],\n",
    "            'model__min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "\n",
    "        grid_rf = GridSearchCV(pipe_rf, param_rf, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "        grid_rf.fit(X, y)\n",
    "        results['Random Forest'] = {\n",
    "            'Best Score': grid_rf.best_score_,\n",
    "            'Best Params': grid_rf.best_params_,\n",
    "            'Best Estimator': grid_rf.best_estimator_\n",
    "        }\n",
    "        print(\"Random Forest Grid Search Completed\")\n",
    "\n",
    "    if Model in ['XGB', 'All']:\n",
    "        pipe_xgb = Pipeline([\n",
    "            ('model', XGBRegressor(objective='reg:squarederror', random_state=42, verbosity=0))\n",
    "        ])\n",
    "        param_xgb = {\n",
    "            'model__learning_rate': [0.01, 0.1, 0.3],\n",
    "            'model__max_depth': [3, 7],\n",
    "            'model__n_estimators': [50, 100],\n",
    "            'model__subsample': [0.7, 1.0],\n",
    "            'model__colsample_bytree': [0.7, 1.0],\n",
    "            'model__reg_alpha': [0, 0.1],\n",
    "            'model__reg_lambda': [0, 0.1]\n",
    "        }\n",
    "\n",
    "        grid_xgb = GridSearchCV(pipe_xgb, param_xgb, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "        grid_xgb.fit(X, y)\n",
    "        results['XGBoost'] = {\n",
    "            'Best Score': grid_xgb.best_score_,\n",
    "            'Best Params': grid_xgb.best_params_,\n",
    "            'Best Estimator': grid_xgb.best_estimator_\n",
    "        }\n",
    "        print(\"XGBoost Grid Search Completed\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83edd54a",
   "metadata": {},
   "source": [
    "# Alasan Pemilihan Fitur\n",
    "Berdasarkan EDA Tentang Korelasi Fitur kita mendapatkan bahwa ada 9 Fitur yang dapat nilai korelasinya diatas 0.5 yaitu\n",
    "Drivewheel, Wheelbase, Carlength, Carwidth, Curbwheight, Enginesize, Fuelsystem, Boreratio,Horsepower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e4396b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Grid Search Completed\n",
      "XGBoost Grid Search Completed\n",
      "\n",
      "=== Summary of Grid Search Results ===\n",
      "| Model         |   Best Score | Best Params                                                                                                                                                                             |\n",
      "|:--------------|-------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| Random Forest |     0.923629 | {'model__max_depth': None, 'model__max_features': 'sqrt', 'model__max_leaf_nodes': None, 'model__max_samples': None, 'model__min_samples_split': 2, 'model__n_estimators': 50}          |\n",
      "| XGBoost       |     0.921015 | {'model__colsample_bytree': 0.7, 'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__n_estimators': 50, 'model__reg_alpha': 0, 'model__reg_lambda': 0, 'model__subsample': 0.7} |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/CarPrice_Assignment_cleaned.csv')\n",
    "X = df[['drivewheel', 'wheelbase', 'carlength', 'carwidth', 'curbweight',\n",
    "         'enginesize', 'fuelsystem', 'boreratio', 'horsepower']]\n",
    "y = df['price']\n",
    "\n",
    "resultsRF = grid_search_models(X, y, Model='RF')\n",
    "resultsXGB = grid_search_models(X, y, Model='XGB')\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost'],\n",
    "    'Best Score': [resultsRF['Random Forest']['Best Score'], resultsXGB['XGBoost']['Best Score']],\n",
    "    'Best Params': [resultsRF['Random Forest']['Best Params'], resultsXGB['XGBoost']['Best Params']]\n",
    "})\n",
    "\n",
    "# Tampilkan tabel\n",
    "print(\"\\n=== Summary of Grid Search Results ===\")\n",
    "print(summary.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68f54800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/29 20:33:14 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 1.3.0 <= scikit-learn <= 1.7.0, but the installed version is 1.7.1. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n",
      "2025/07/29 20:33:15 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/07/29 20:33:15 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        'cv_splits': 5,\n",
    "        'scoring': 'r2',\n",
    "        'Model': 'All'\n",
    "    })\n",
    "    mlflow.log_metric('Random Forest Best Score', resultsRF['Random Forest']['Best Score'])\n",
    "    mlflow.log_param('Random Forest Best Params', resultsRF['Random Forest']['Best Params'])\n",
    "    mlflow.log_metric('XGBoost Best Score', resultsXGB['XGBoost']['Best Score'])\n",
    "    mlflow.log_param('XGBoost Best Params', resultsXGB['XGBoost']['Best Params'])\n",
    "    \n",
    "    # Autologging untuk menyimpan model\n",
    "mlflow.autolog()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
